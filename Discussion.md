# Efficient Log Retrieval from a Large File  

## ğŸ“Œ Problem Statement  
We need to extract logs efficiently from a **1TB log file** where logs are evenly distributed across dates. The solution must be optimized for **speed** and **memory usage**, ensuring that retrieving logs for a specific date is as fast as possible.  

---

## ğŸ” **Approaches Considered**  

### 1ï¸âƒ£ **Naive Approach (Line-by-Line Scan)**
**ğŸ“Œ Idea:**  
- Open the log file and scan every line.
- Check if the line starts with the required date.
- If yes, store it in an output file.  

**âŒ Drawbacks:**  
- **O(N) time complexity** (where N is the number of lines).  
- Inefficient for a **1TB** file as it requires reading the entire file even if we only need a small portion.  
- **Memory inefficient** since it holds unnecessary logs in memory.  

---

### 2ï¸âƒ£ **Indexing-Based Approach (Final Solution)**
**ğŸ“Œ Idea:**  
- Create an **index file** mapping **dates â†’ byte positions** in the log file.  
- Use **binary search** to quickly locate the starting position for a given date.  
- Extract logs **without scanning unnecessary lines**.  

**âœ… Advantages:**  
- **O(log N) lookup time** due to binary search.  
- Only reads **relevant logs**, improving efficiency.  
- **Minimal memory usage**, as we only store the index in RAM.  

---

## ğŸ† **Final Solution Explanation**  
Our final solution follows **three main steps:**  

### **1ï¸âƒ£ Index Creation**  
- We **scan the log file once** and store the **byte position** where each date begins.  
- This is stored in a separate `log_index.txt` file.  
- It ensures **fast lookups** in future queries.  

### **2ï¸âƒ£ Fast Log Extraction**  
- We **load the index into memory**.  
- We perform a **binary search** to locate the starting position of the requested date.  
- We read logs **only for that date** and stop as soon as the date changes.  

### **3ï¸âƒ£ Efficient Storage & Retrieval**  
- Extracted logs are saved in `output/output_YYYY-MM-DD.txt`.  
- If the index doesnâ€™t exist, it's created automatically.  

---

## ğŸš€ **Performance Analysis**  
| Approach         | Time Complexity | Space Complexity | Scalability |
|-----------------|---------------|----------------|-------------|
| Naive Scan      | O(N)          | O(1)           | ğŸš¨ Slow for large files |
| Indexed Lookup  | O(log N) + O(M) | O(log N) (index size) | âš¡ Fast & Efficient |

- **N = Total number of log entries**  
- **M = Number of log entries on the requested date**  

---

## ğŸ›  **How to Run the Script?**  
### **ğŸ”¹ Step 1: Download the Log File**

###Project Structure
/log-extractor
â”‚â”€â”€ src/
â”‚   â”œâ”€â”€ extract_logs.py   # Main log extraction script
â”‚â”€â”€ README.md             # Instructions & setup
â”‚â”€â”€ DISCUSSION.md         # This file (Solution discussion)
â”‚â”€â”€ test_logs.log         # Sample log file
â”‚â”€â”€ log_index.txt         # Auto-generated index file
â”‚â”€â”€ output/               # Extracted logs output folder

## ğŸ”¥ Why This Approach?  

âœ… **Scalability**  
   - Designed to handle **1TB+ log files** efficiently without excessive disk reads.  

âœ… **Optimized Retrieval**  
   - **Uses indexing & binary search** for fast lookups, reducing search time from **O(N) to O(log N)**.  
   - Reads only the relevant portion of the file instead of scanning the entire log.  

âœ… **Minimal Memory Usage**  
   - Loads only the **index file** (a few MBs) into RAM, making it highly **memory efficient**.  
   - Doesn't store unnecessary logs in memoryâ€”everything is processed **line by line**.  

ğŸš€ **With this approach, extracting logs for a specific date takes only a few seconds, even from a 1TB file!**  
